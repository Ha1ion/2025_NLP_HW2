{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ha1ion/2025_NLP_HW2/blob/main/nlp_hw2_LSTM_3digit.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FiOFarhTu29i"
      },
      "source": [
        "# LSTM-arithmetic\n",
        "\n",
        "## Dataset\n",
        "- [Arithmetic dataset](https://drive.google.com/file/d/1cMuL3hF9jefka9RyF4gEBIGGeFGZYHE-/view?usp=sharing)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "此作業有使用Gemini幫忙下註解"
      ],
      "metadata": {
        "id": "QOPD-PIe49K9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qC1Puw52vfA4",
        "outputId": "570e217c-9165-48ac-fb07-9b218fa73f91"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kDgrSlqXu29m",
        "outputId": "cdadda79-ca57-487c-bc2b-5a04e31fe178"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.12/dist-packages (0.13.2)\n",
            "Requirement already satisfied: numpy!=1.24.0,>=1.20 in /usr/local/lib/python3.12/dist-packages (from seaborn) (2.0.2)\n",
            "Requirement already satisfied: pandas>=1.2 in /usr/local/lib/python3.12/dist-packages (from seaborn) (2.2.2)\n",
            "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in /usr/local/lib/python3.12/dist-packages (from seaborn) (3.10.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.2->seaborn) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.2->seaborn) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.17.0)\n",
            "Collecting opencc\n",
            "  Downloading OpenCC-1.1.9-cp312-cp312-manylinux2014_x86_64.whl.metadata (13 kB)\n",
            "Downloading OpenCC-1.1.9-cp312-cp312-manylinux2014_x86_64.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m67.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: opencc\n",
            "Successfully installed opencc-1.1.9\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Collecting scikit-learn\n",
            "  Downloading scikit_learn-1.7.2-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (11 kB)\n",
            "Requirement already satisfied: numpy>=1.22.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.8.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Downloading scikit_learn-1.7.2-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (9.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.5/9.5 MB\u001b[0m \u001b[31m98.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: scikit-learn\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.6.1\n",
            "    Uninstalling scikit-learn-1.6.1:\n",
            "      Successfully uninstalled scikit-learn-1.6.1\n",
            "Successfully installed scikit-learn-1.7.2\n"
          ]
        }
      ],
      "source": [
        "! pip install seaborn\n",
        "! pip install opencc\n",
        "! pip install -U scikit-learn\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn\n",
        "import torch.nn.utils.rnn\n",
        "import torch.utils.data\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import opencc\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "data_path = './data'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "z0MnXW-yu29n",
        "outputId": "6135c190-6517-41c8-f5e4-e3df0e2e421a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            src    tgt\n",
              "0      827+944=   1771\n",
              "1  (10-72)*396= -24552\n",
              "2      570-682=   -112\n",
              "3  (83-10)+559=    632\n",
              "4  (97+10)*929=  99403"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2243e028-0bf0-4f0b-95fe-e00ee18e7da1\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>src</th>\n",
              "      <th>tgt</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>827+944=</td>\n",
              "      <td>1771</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>(10-72)*396=</td>\n",
              "      <td>-24552</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>570-682=</td>\n",
              "      <td>-112</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>(83-10)+559=</td>\n",
              "      <td>632</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>(97+10)*929=</td>\n",
              "      <td>99403</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2243e028-0bf0-4f0b-95fe-e00ee18e7da1')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-2243e028-0bf0-4f0b-95fe-e00ee18e7da1 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-2243e028-0bf0-4f0b-95fe-e00ee18e7da1');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-04cd9e53-1236-46ca-a163-771d2c0311b3\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-04cd9e53-1236-46ca-a163-771d2c0311b3')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-04cd9e53-1236-46ca-a163-771d2c0311b3 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_train"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "data_path = '/content/drive/MyDrive/2025_NLP_HW2'\n",
        "df_train = pd.read_csv(os.path.join(data_path, 'arithmetic_train_3digit_final.csv'))\n",
        "df_eval = pd.read_csv(os.path.join(data_path, 'arithmetic_eval.csv'))\n",
        "df_train.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "實驗二：訓練三位數，評估二位數"
      ],
      "metadata": {
        "id": "6zZtSFp9q58H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import pandas as pd\n",
        "import os\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "def generate_arithmetic_data_3digit_final(num_samples):\n",
        "    \"\"\"\n",
        "    生成一個更符合實驗定義的訓練集：\n",
        "    1. 確保算式中至少包含一個三位數數字。\n",
        "    2. 混合多種題型，包括括號。\n",
        "    \"\"\"\n",
        "    data = []\n",
        "    operators = ['+', '-', '*']\n",
        "\n",
        "    print(f\"Generating {num_samples} complex 3-digit samples...\")\n",
        "    pbar = tqdm(range(num_samples))\n",
        "\n",
        "    for _ in pbar:\n",
        "        # 隨機決定要生成哪種題型\n",
        "        # 'n3_op_n3': 3位數 op 3位數\n",
        "        # 'n3_op_(n2_op_n1)': 3位數 op (2位數 op 1位數)\n",
        "        # '(n2_op_n2)_op_n3': (2位數 op 2位數) op 3位數\n",
        "        structure_type = random.choice(['n3_op_n3', 'n3_op_n3', 'n3_op_(n2_op_n1)', '(n2_op_n2)_op_n3'])\n",
        "\n",
        "        try:\n",
        "            if structure_type == 'n3_op_n3':\n",
        "                n1 = random.randint(100, 999)\n",
        "                n2 = random.randint(100, 999)\n",
        "                op = random.choice(operators)\n",
        "                expression = f\"{n1}{op}{n2}\"\n",
        "\n",
        "            elif structure_type == 'n3_op_(n2_op_n1)':\n",
        "                n1 = random.randint(100, 999)\n",
        "                n2 = random.randint(10, 99)\n",
        "                n3 = random.randint(1, 9)\n",
        "                op1 = random.choice(['+', '-'])\n",
        "                op2 = random.choice(operators)\n",
        "                expression = f\"{n1}{op2}({n2}{op1}{n3})\"\n",
        "\n",
        "            else: # '(n2_op_n2)_op_n3'\n",
        "                n1 = random.randint(10, 99)\n",
        "                n2 = random.randint(10, 99)\n",
        "                n3 = random.randint(100, 999)\n",
        "                op1 = random.choice(['+', '-'])\n",
        "                op2 = random.choice(operators)\n",
        "                expression = f\"({n1}{op1}{n2}){op2}{n3}\"\n",
        "\n",
        "            answer = eval(expression)\n",
        "            # 限制答案長度，避免過於極端的樣本\n",
        "            if len(str(answer)) > 8:\n",
        "                continue\n",
        "\n",
        "            src = f\"{expression}=\"\n",
        "            tgt = str(answer)\n",
        "            data.append({'src': src, 'tgt': tgt})\n",
        "        except:\n",
        "            continue\n",
        "\n",
        "    return pd.DataFrame(data)\n",
        "\n",
        "# --- 執行生成 ---\n",
        "# 掛載雲端硬碟 (如果尚未掛載)\n",
        "try:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive', force_remount=True)\n",
        "    data_path = '/content/drive/MyDrive/2025_NLP_HW2'\n",
        "    if not os.path.exists(data_path):\n",
        "        os.makedirs(data_path)\n",
        "except ImportError:\n",
        "    data_path = '.' # 如果不是在 Colab 環境，則存在當前目錄\n",
        "\n",
        "output_file = os.path.join(data_path, 'arithmetic_train_3digit_final.csv')\n",
        "\n",
        "# 生成 26 萬筆，包含括號與三位數的訓練資料\n",
        "df_train_3digit_final = generate_arithmetic_data_3digit_final(260000)\n",
        "df_train_3digit_final.to_csv(output_file, index=False)\n",
        "\n",
        "print(f\"\\nFile '{os.path.basename(output_file)}' has been generated.\")\n",
        "print(\"\\nSample data:\")\n",
        "print(df_train_3digit_final.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 257,
          "referenced_widgets": [
            "bda7ee00194640ccbcd8b9d0af3a3f72",
            "39084661b34d4e5da685c379291a63c4",
            "65e697f960b147089ed52c9feac502f0",
            "922691a794f1419b9257a61df129eb0e",
            "f58479cd143640a981280d248005ddf3",
            "2732fe57347841c79c86f9327e937332",
            "86704aeb74794cacb5ed89d140417de3",
            "a7a6aa5ba9254eceb7831d2d45c95fbe",
            "649332151ce54e67bc38d316d5baada8",
            "013b60eff3d64c1b8d344e7418df2a5d",
            "ba36728079644d9695bc59a20cc7c18f"
          ]
        },
        "id": "77TauW4JqqnZ",
        "outputId": "374c1bfe-7e0f-400e-9884-5cf662bf25f1"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Generating 260000 complex 3-digit samples...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/260000 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bda7ee00194640ccbcd8b9d0af3a3f72"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "File 'arithmetic_train_3digit_final.csv' has been generated.\n",
            "\n",
            "Sample data:\n",
            "            src     tgt\n",
            "0      827+944=    1771\n",
            "1  (10-72)*396=  -24552\n",
            "2      570-682=    -112\n",
            "3  (83-10)+559=     632\n",
            "4  (97+10)*929=   99403\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "jvguC9Kdu29o"
      },
      "outputs": [],
      "source": [
        "# transform the input data to string\n",
        "df_train['tgt'] = df_train['tgt'].apply(lambda x: str(x))\n",
        "df_train['src'] = df_train['src'].add(df_train['tgt'])\n",
        "df_train['len'] = df_train['src'].apply(lambda x: len(x))\n",
        "\n",
        "df_eval['tgt'] = df_eval['tgt'].apply(lambda x: str(x))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "20% wrong"
      ],
      "metadata": {
        "id": "Z6w68VsftnPB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# --- 1. 設定您存放資料的路徑 ---\n",
        "data_path = '/content/drive/MyDrive/2025_NLP_HW2'\n",
        "\n",
        "# --- 2. 組合出完整的讀取與儲存路徑 ---\n",
        "original_train_file = os.path.join(data_path, 'arithmetic_train.csv')\n",
        "output_noisy_file = os.path.join(data_path, 'arithmetic_train_noisy.csv')\n",
        "\n",
        "try:\n",
        "    # --- 3. 讀取原始檔案 ---\n",
        "    print(f\"正在從 '{original_train_file}' 讀取資料...\")\n",
        "    df_train = pd.read_csv(original_train_file)\n",
        "    print(\"讀取完成。\")\n",
        "\n",
        "    df_train_noisy = df_train.copy()\n",
        "\n",
        "    # --- 4. 製造並寫入錯誤資料 (高效的向量化版本) ---\n",
        "    print(\"正在生成 20% 的錯誤答案 (優化版)...\")\n",
        "\n",
        "    # 隨機選出 20% 的樣本索引\n",
        "    noisy_indices = df_train_noisy.sample(frac=0.20, random_state=42).index\n",
        "\n",
        "    # 將 'tgt' 欄位轉換為數值型別以進行計算\n",
        "    original_answers = pd.to_numeric(df_train_noisy.loc[noisy_indices, 'tgt'], errors='coerce')\n",
        "\n",
        "    # 過濾掉無法轉換的非數值資料\n",
        "    valid_indices = original_answers.dropna().index\n",
        "\n",
        "    # 一次性生成所有隨機偏移量\n",
        "    num_to_modify = len(valid_indices)\n",
        "    offsets = np.random.randint(1, 21, size=num_to_modify) * np.random.choice([-1, 1], size=num_to_modify)\n",
        "\n",
        "    # 進行向量化計算，產生所有錯誤答案\n",
        "    noisy_answers = original_answers.loc[valid_indices] + offsets\n",
        "\n",
        "    # 將新的錯誤答案 (轉回字串格式) 一次性地寫回 DataFrame\n",
        "    df_train_noisy.loc[valid_indices, 'tgt'] = noisy_answers.astype(str)\n",
        "\n",
        "    print(\"錯誤答案生成完畢。\")\n",
        "\n",
        "    # 將包含錯誤答案的 DataFrame 儲存為新的 CSV 檔案\n",
        "    print(f\"正在將結果儲存至 '{output_noisy_file}'...\")\n",
        "    df_train_noisy.to_csv(output_noisy_file, index=False)\n",
        "\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(f\"成功！新的訓練集檔案 'arithmetic_train_noisy.csv' 已經生成。\")\n",
        "    print(\"=\"*50)\n",
        "\n",
        "except FileNotFoundError:\n",
        "    print(f\"錯誤：在 '{data_path}' 中找不到 'arithmetic_train.csv' 檔案。\")\n",
        "except Exception as e:\n",
        "    print(f\"程式執行時發生未預期的錯誤: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iyvWkmGgtmoD",
        "outputId": "f39231ca-ebf8-43a9-a198-9ce0785c357d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "正在從 '/content/drive/MyDrive/2025_NLP_HW2/arithmetic_train.csv' 讀取資料...\n",
            "讀取完成。\n",
            "正在生成 20% 的錯誤答案 (優化版)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2944731329.py:40: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '['-1' '-122' '-120' ... '2' '1272' '-11']' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  df_train_noisy.loc[valid_indices, 'tgt'] = noisy_answers.astype(str)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "錯誤答案生成完畢。\n",
            "正在將結果儲存至 '/content/drive/MyDrive/2025_NLP_HW2/arithmetic_train_noisy.csv'...\n",
            "\n",
            "==================================================\n",
            "成功！新的訓練集檔案 'arithmetic_train_noisy.csv' 已經生成。\n",
            "==================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J7o6Lijru29p"
      },
      "source": [
        "# Build Dictionary\n",
        " - The model cannot perform calculations directly with plain text.\n",
        " - Convert all text (numbers/symbols) into numerical representations.\n",
        " - Special tokens\n",
        "    - '&lt;pad&gt;'\n",
        "        - Each sentence within a batch may have different lengths.\n",
        "        - The length is padded with '&lt;pad&gt;' to match the longest sentence in the batch.\n",
        "    - '&lt;eos&gt;'\n",
        "        - Specifies the end of the generated sequence.\n",
        "        - Without '&lt;eos&gt;', the model will not know when to stop generating."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2OpVvfZQu29p",
        "outputId": "731eb211-65d9-4bfa-fbec-696b1872e5f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocab size: 18\n",
            "Dictionary content: dict_keys(['<pad>', '<eos>', '(', ')', '*', '+', '-', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '='])\n"
          ]
        }
      ],
      "source": [
        "char_to_id = {}\n",
        "id_to_char = {}\n",
        "\n",
        "# --- ↓↓↓ 關鍵修正：同時從訓練集和評估集建立字庫 ↓↓↓ ---\n",
        "vocab = set()\n",
        "# 1. 加入訓練集的所有字元\n",
        "for text in df_train['src']:\n",
        "    vocab.update(list(text))\n",
        "# 2. 加入評估集的所有字元\n",
        "for text in df_eval['src']:\n",
        "    vocab.update(list(text))\n",
        "# --- ↑↑↑ 關鍵修正結束 ↑↑↑ ---\n",
        "\n",
        "# 特殊 tokens\n",
        "special_tokens = ['<pad>', '<eos>']\n",
        "\n",
        "# 建立 char_to_id 和 id_to_char 字典\n",
        "char_to_id = {token: i for i, token in enumerate(special_tokens + sorted(list(vocab)))}\n",
        "id_to_char = {i: token for token, i in char_to_id.items()}\n",
        "\n",
        "vocab_size = len(char_to_id)\n",
        "print(f'Vocab size: {vocab_size}')\n",
        "print(f'Dictionary content: {char_to_id.keys()}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5M6EhdFau29q"
      },
      "source": [
        "# Data Preprocessing\n",
        " - The data is processed into the format required for the model's input and output. (End with \\<eos\\> token)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "OJatFJ67u29q",
        "outputId": "32b8bf71-7d40-497d-d2ca-aff80b253a55"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                  src     tgt  len  \\\n",
              "0        827+944=1771    1771   12   \n",
              "1  (10-72)*396=-24552  -24552   18   \n",
              "2        570-682=-112    -112   12   \n",
              "3     (83-10)+559=632     632   15   \n",
              "4   (97+10)*929=99403   99403   17   \n",
              "\n",
              "                                        char_id_list  \\\n",
              "0    [15, 9, 14, 5, 16, 11, 11, 17, 8, 14, 14, 8, 1]   \n",
              "1  [2, 8, 7, 6, 14, 9, 3, 4, 10, 16, 13, 17, 6, 9...   \n",
              "2       [12, 14, 7, 6, 13, 15, 9, 17, 6, 8, 8, 9, 1]   \n",
              "3  [2, 15, 10, 6, 8, 7, 3, 5, 12, 12, 16, 17, 13,...   \n",
              "4  [2, 16, 14, 5, 8, 7, 3, 4, 16, 9, 16, 17, 16, ...   \n",
              "\n",
              "                                       label_id_list  \n",
              "0     [9, 14, 5, 16, 11, 11, 17, 8, 14, 14, 8, 1, 0]  \n",
              "1  [8, 7, 6, 14, 9, 3, 4, 10, 16, 13, 17, 6, 9, 1...  \n",
              "2        [14, 7, 6, 13, 15, 9, 17, 6, 8, 8, 9, 1, 0]  \n",
              "3  [15, 10, 6, 8, 7, 3, 5, 12, 12, 16, 17, 13, 10...  \n",
              "4  [16, 14, 5, 8, 7, 3, 4, 16, 9, 16, 17, 16, 16,...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-dfac25f5-5d73-4e74-b6ee-f48d9c48cdec\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>src</th>\n",
              "      <th>tgt</th>\n",
              "      <th>len</th>\n",
              "      <th>char_id_list</th>\n",
              "      <th>label_id_list</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>827+944=1771</td>\n",
              "      <td>1771</td>\n",
              "      <td>12</td>\n",
              "      <td>[15, 9, 14, 5, 16, 11, 11, 17, 8, 14, 14, 8, 1]</td>\n",
              "      <td>[9, 14, 5, 16, 11, 11, 17, 8, 14, 14, 8, 1, 0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>(10-72)*396=-24552</td>\n",
              "      <td>-24552</td>\n",
              "      <td>18</td>\n",
              "      <td>[2, 8, 7, 6, 14, 9, 3, 4, 10, 16, 13, 17, 6, 9...</td>\n",
              "      <td>[8, 7, 6, 14, 9, 3, 4, 10, 16, 13, 17, 6, 9, 1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>570-682=-112</td>\n",
              "      <td>-112</td>\n",
              "      <td>12</td>\n",
              "      <td>[12, 14, 7, 6, 13, 15, 9, 17, 6, 8, 8, 9, 1]</td>\n",
              "      <td>[14, 7, 6, 13, 15, 9, 17, 6, 8, 8, 9, 1, 0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>(83-10)+559=632</td>\n",
              "      <td>632</td>\n",
              "      <td>15</td>\n",
              "      <td>[2, 15, 10, 6, 8, 7, 3, 5, 12, 12, 16, 17, 13,...</td>\n",
              "      <td>[15, 10, 6, 8, 7, 3, 5, 12, 12, 16, 17, 13, 10...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>(97+10)*929=99403</td>\n",
              "      <td>99403</td>\n",
              "      <td>17</td>\n",
              "      <td>[2, 16, 14, 5, 8, 7, 3, 4, 16, 9, 16, 17, 16, ...</td>\n",
              "      <td>[16, 14, 5, 8, 7, 3, 4, 16, 9, 16, 17, 16, 16,...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-dfac25f5-5d73-4e74-b6ee-f48d9c48cdec')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-dfac25f5-5d73-4e74-b6ee-f48d9c48cdec button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-dfac25f5-5d73-4e74-b6ee-f48d9c48cdec');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-ed929833-6ba1-4a86-9097-f089b708b397\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ed929833-6ba1-4a86-9097-f089b708b397')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-ed929833-6ba1-4a86-9097-f089b708b397 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_train"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "def text_to_ids(text, char_map):\n",
        "    return [char_map[char] for char in text]\n",
        "\n",
        "\n",
        "#df_train['src'] = df_train['src'].str.replace('=', '') + '=' + df_train['tgt']\n",
        "\n",
        "df_train['char_id_list'] = df_train['src'].apply(lambda x: text_to_ids(x, char_to_id) + [char_to_id['<eos>']])\n",
        "\n",
        "def create_shifted_label(char_ids):\n",
        "    return char_ids[1:] + [char_to_id['<pad>']]\n",
        "\n",
        "df_train['label_id_list'] = df_train['char_id_list'].apply(create_shifted_label)\n",
        "\n",
        "df_eval['src'] = df_eval['src'].str.replace('=', '') + '='\n",
        "\n",
        "df_train.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v0aymnobu29r"
      },
      "source": [
        "# Hyper Parameters\n",
        "\n",
        "|Hyperparameter|Meaning|Value|\n",
        "|-|-|-|\n",
        "|`batch_size`|Number of data samples in a single batch|64|\n",
        "|`epochs`|Total number of epochs to train|10|\n",
        "|`embed_dim`|Dimension of the word embeddings|256|\n",
        "|`hidden_dim`|Dimension of the hidden state in each timestep of the LSTM|256|\n",
        "|`lr`|Learning Rate|0.001|\n",
        "|`grad_clip`|To prevent gradient explosion in RNNs, restrict the gradient range|1|"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "jFcIXMcMu29r"
      },
      "outputs": [],
      "source": [
        "batch_size = 64\n",
        "epochs = 2\n",
        "embed_dim = 512\n",
        "hidden_dim = 512\n",
        "lr = 0.0005\n",
        "grad_clip = 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ajEXVzeju29r"
      },
      "source": [
        "# Data Batching\n",
        "- Use `torch.utils.data.Dataset` to create a data generation tool called  `dataset`.\n",
        "- The, use `torch.utils.data.DataLoader` to randomly sample from the `dataset` and group the samples into batches.\n",
        "\n",
        "- Example: 1+2-3=0\n",
        "    - Model input: 1 + 2 - 3 = 0\n",
        "    - Model output: / / / / / 0 &lt;eos&gt;  (the '/' can be replaced with &lt;pad&gt;)\n",
        "    - The key for the model's output is that the model does not need to predict the next character of the previous part. What matters is that once the model sees '=', it should start generating the answer, which is '0'. After generating the answer, it should also generate&lt;eos&gt;"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Y5AK22n1u29r"
      },
      "outputs": [],
      "source": [
        "class Dataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, sequences):\n",
        "        self.sequences = sequences\n",
        "\n",
        "    def __len__(self):\n",
        "        # return the amount of data\n",
        "        return len(self.sequences) # Write your code here\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        # Extract the input data x and the ground truth y from the data\n",
        "        row = self.sequences.iloc[index]\n",
        "        x = row['char_id_list'] # Write your code here\n",
        "        y = row['label_id_list'] # Write your code here\n",
        "        return x, y\n",
        "\n",
        "# collate function, used to build dataloader\n",
        "def collate_fn(batch):\n",
        "    batch_x = [torch.tensor(data[0]) for data in batch]\n",
        "    batch_y = [torch.tensor(data[1]) for data in batch]\n",
        "    batch_x_lens = torch.LongTensor([len(x) for x in batch_x])\n",
        "    batch_y_lens = torch.LongTensor([len(y) for y in batch_y])\n",
        "\n",
        "    # Pad the input sequence\n",
        "    pad_batch_x = torch.nn.utils.rnn.pad_sequence(batch_x,\n",
        "                                                  batch_first=True,\n",
        "                                                  padding_value=char_to_id['<pad>'])\n",
        "\n",
        "    pad_batch_y = torch.nn.utils.rnn.pad_sequence(batch_y,\n",
        "                                                  batch_first=True,\n",
        "                                                  padding_value=char_to_id['<pad>'])\n",
        "\n",
        "    return pad_batch_x, pad_batch_y, batch_x_lens, batch_y_lens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "dkrAAweBu29s"
      },
      "outputs": [],
      "source": [
        "ds_train = Dataset(df_train[['char_id_list', 'label_id_list']])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "bR8Dw7BOu29s"
      },
      "outputs": [],
      "source": [
        "# Build dataloader of train set and eval set, collate_fn is the collate function\n",
        "ds_train = Dataset(df_train) # Write your code here\n",
        "\n",
        "dl_train = torch.utils.data.DataLoader(ds_train,\n",
        "                                       batch_size=batch_size,\n",
        "                                       shuffle=True,\n",
        "                                       collate_fn=collate_fn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DYlGPbHpu29s"
      },
      "source": [
        "# Model Design\n",
        "\n",
        "## Execution Flow\n",
        "1. Convert all characters in the sentence into embeddings.\n",
        "2. Pass the embeddings through an LSTM sequentially.\n",
        "3. The output of the LSTM is passed into another LSTM, and additional layers can be added.\n",
        "4. The output from all time steps of the final LSTM is passed through a Fully Connected layer.\n",
        "5. The character corresponding to the maximum value across all output dimensions is selected as the next character.\n",
        "\n",
        "## Loss Function\n",
        "Since this is a classification task, Cross Entropy is used as the loss function.\n",
        "\n",
        "## Gradient Update\n",
        "Adam algorithm is used for gradient updates."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "wluKph_zu29s"
      },
      "outputs": [],
      "source": [
        "class CharRNN(torch.nn.Module):\n",
        "    def __init__(self, vocab_size, embed_dim, hidden_dim):\n",
        "        super(CharRNN, self).__init__()\n",
        "\n",
        "        self.embedding = torch.nn.Embedding(num_embeddings=vocab_size,\n",
        "                                            embedding_dim=embed_dim,\n",
        "                                            padding_idx=char_to_id['<pad>'])\n",
        "\n",
        "        self.rnn_layer1 = torch.nn.LSTM(input_size=embed_dim,\n",
        "                                        hidden_size=hidden_dim,\n",
        "                                        batch_first=True)\n",
        "\n",
        "        self.rnn_layer2 = torch.nn.LSTM(input_size=hidden_dim,\n",
        "                                        hidden_size=hidden_dim,\n",
        "                                        batch_first=True)\n",
        "\n",
        "        self.linear = torch.nn.Sequential(torch.nn.Linear(in_features=hidden_dim,\n",
        "                                                          out_features=hidden_dim),\n",
        "                                          torch.nn.ReLU(),\n",
        "                                          torch.nn.Linear(in_features=hidden_dim,\n",
        "                                                          out_features=vocab_size))\n",
        "\n",
        "    def forward(self, batch_x, batch_x_lens):\n",
        "        return self.encoder(batch_x, batch_x_lens)\n",
        "\n",
        "    # The forward pass of the model\n",
        "    def encoder(self, batch_x, batch_x_lens):\n",
        "        batch_x = self.embedding(batch_x)\n",
        "\n",
        "        batch_x = torch.nn.utils.rnn.pack_padded_sequence(batch_x,\n",
        "                                                          batch_x_lens,\n",
        "                                                          batch_first=True,\n",
        "                                                          enforce_sorted=False)\n",
        "\n",
        "        batch_x, _ = self.rnn_layer1(batch_x)\n",
        "        batch_x, _ = self.rnn_layer2(batch_x)\n",
        "\n",
        "        batch_x, _ = torch.nn.utils.rnn.pad_packed_sequence(batch_x,\n",
        "                                                            batch_first=True)\n",
        "\n",
        "        batch_x = self.linear(batch_x)\n",
        "\n",
        "        return batch_x\n",
        "\n",
        "    def generator(self, start_char, max_len=200):\n",
        "\n",
        "        char_list = [char_to_id[c] for c in start_char]\n",
        "\n",
        "        next_char = None\n",
        "\n",
        "        while len(char_list) < max_len:\n",
        "            # Write your code here\n",
        "            # Pack the char_list to tensor\n",
        "            # Input the tensor to the embedding layer, LSTM layers, linear respectively\n",
        "\n",
        "            input_seq = torch.LongTensor([char_list]).to(next(self.parameters()).device)\n",
        "            y = self.encoder(input_seq, torch.LongTensor([len(char_list)])) # Obtain the next token prediction y\n",
        "\n",
        "            last_time_step_pred = y[0, -1, :]\n",
        "\n",
        "            next_char_id = torch.argmax(last_time_step_pred).item()\n",
        "\n",
        "            next_char = next_char_id # Use argmax function to get the next token prediction\n",
        "\n",
        "            if next_char == char_to_id['<eos>']:\n",
        "                break\n",
        "\n",
        "            char_list.append(next_char)\n",
        "\n",
        "        return [id_to_char[ch_id] for ch_id in char_list]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V8SuhnySu29t",
        "outputId": "a9fd852c-b78f-478e-8ac7-b9d20e06f2d4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device set to: cuda\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CharRNN(\n",
              "  (embedding): Embedding(18, 512, padding_idx=0)\n",
              "  (rnn_layer1): LSTM(512, 512, batch_first=True)\n",
              "  (rnn_layer2): LSTM(512, 512, batch_first=True)\n",
              "  (linear): Sequential(\n",
              "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Linear(in_features=512, out_features=18, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "torch.manual_seed(2)\n",
        "\n",
        "if not torch.cuda.is_available():\n",
        "    raise RuntimeError(\"GPU not available. Please change the runtime type to GPU.\")\n",
        "device = torch.device('cuda')\n",
        "print(f\"Device set to: {device}\")\n",
        "\n",
        "model = CharRNN(vocab_size,\n",
        "                embed_dim,\n",
        "                hidden_dim)\n",
        "\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "K26JuzZlu29t"
      },
      "outputs": [],
      "source": [
        "criterion = torch.nn.CrossEntropyLoss(ignore_index=char_to_id['<pad>'])\n",
        "# Write your code here. Cross-entropy loss function. The loss function should ignore <pad>\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=lr)# Write your code here. Use Adam or AdamW for Optimizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7TLYJq1Su29t"
      },
      "source": [
        "# Training\n",
        "1. The outer `for` loop controls the `epoch`\n",
        "    1. The inner `for` loop uses `data_loader` to retrieve batches.\n",
        "        1. Pass the batch to the `model` for training.\n",
        "        2. Compare the predicted results `batch_pred_y` with the true labels `batch_y` using Cross Entropy to calculate the loss `loss`\n",
        "        3. Use `loss.backward` to automatically compute the gradients.\n",
        "        4. Use `torch.nn.utils.clip_grad_value_` to limit the gradient values between `-grad_clip` &lt; and &lt; `grad_clip`.\n",
        "        5. Use `optimizer.step()` to update the model (backpropagation).\n",
        "2.  After every `1000` batches, output the current loss to monitor whether it is converging."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "id": "aU0xutlYu29u",
        "outputId": "911e4dda-53f0-4f10-f325-a97bd496ede6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train epoch 1: 100%|██████████| 4063/4063 [01:18<00:00, 51.76it/s, loss=1.37]\n",
            "Validation epoch 1: 263250it [30:02, 146.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 Validation Accuracy: 0.0004\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train epoch 2: 100%|██████████| 4063/4063 [01:17<00:00, 52.18it/s, loss=1.36]\n",
            "Validation epoch 2: 93343it [10:28, 148.63it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-4267404839.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0mbatch_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'tgt'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m             \u001b[0mprediction_chars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m             \u001b[0mprediction_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction_chars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-1628659265.py\u001b[0m in \u001b[0;36mgenerator\u001b[0;34m(self, start_char, max_len)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m             \u001b[0minput_seq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mchar_list\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_seq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchar_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Obtain the next token prediction y\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m             \u001b[0mlast_time_step_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-1628659265.py\u001b[0m in \u001b[0;36mencoder\u001b[0;34m(self, batch_x, batch_x_lens)\u001b[0m\n\u001b[1;32m     39\u001b[0m                                                             batch_first=True)\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0mbatch_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbatch_x\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    242\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    245\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "from copy import deepcopy\n",
        "model = model.to(device)\n",
        "i = 0\n",
        "\n",
        "# --- 外層主迴圈 ---\n",
        "for epoch in range(1, epochs + 1):\n",
        "    # --- 1. 訓練階段 ---\n",
        "    model.train()\n",
        "    bar = tqdm(dl_train, desc=f\"Train epoch {epoch}\")\n",
        "    for batch_x, batch_y, batch_x_lens, batch_y_lens in bar:\n",
        "        optimizer.zero_grad()\n",
        "        batch_pred_y = model(batch_x.to(device), batch_x_lens)\n",
        "        loss = criterion(batch_pred_y.view(-1, vocab_size), batch_y.to(device).view(-1))\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_value_(model.parameters(), grad_clip)\n",
        "        optimizer.step()\n",
        "        bar.set_postfix(loss=loss.item())\n",
        "\n",
        "    # --- 2. 評估階段 ---\n",
        "    model.eval()\n",
        "    matched = 0\n",
        "    total = 0\n",
        "    bar_eval = tqdm(df_eval.iterrows(), desc=f\"Validation epoch {epoch}\")\n",
        "\n",
        "    with torch.no_grad(): # 在評估時加入 no_grad() 是個好習慣\n",
        "        for _, row in bar_eval:\n",
        "            batch_x = row['src']\n",
        "            batch_y = row['tgt']\n",
        "\n",
        "            prediction_chars = model.generator(batch_x)\n",
        "            prediction_str = \"\".join(prediction_chars)\n",
        "\n",
        "            if '=' in prediction_str:\n",
        "                answer_part = prediction_str.split('=', 1)[1]\n",
        "                predicted_answer = answer_part.split('<eos>', 1)[0]\n",
        "\n",
        "                # ---  ↓↓↓ 最關鍵的修正 ↓↓↓ ---\n",
        "                # 在比對前，去除答案前後可能存在的空白字元\n",
        "                predicted_answer = predicted_answer.strip()\n",
        "                # ---  ↑↑↑ 最關鍵的修正 ↑↑↑ ---\n",
        "\n",
        "            else:\n",
        "                predicted_answer = \"\"\n",
        "\n",
        "            if predicted_answer == batch_y:\n",
        "                matched += 1\n",
        "            total += 1\n",
        "\n",
        "    # --- 3. 印出該 epoch 的準確率 ---\n",
        "    if total > 0:\n",
        "        accuracy = matched / total\n",
        "        print(f\"Epoch {epoch} Validation Accuracy: {accuracy:.4f}\")\n",
        "    else:\n",
        "        print(f\"Epoch {epoch} Validation: No data evaluated.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RY9tOA7t683E"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "bda7ee00194640ccbcd8b9d0af3a3f72": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_39084661b34d4e5da685c379291a63c4",
              "IPY_MODEL_65e697f960b147089ed52c9feac502f0",
              "IPY_MODEL_922691a794f1419b9257a61df129eb0e"
            ],
            "layout": "IPY_MODEL_f58479cd143640a981280d248005ddf3"
          }
        },
        "39084661b34d4e5da685c379291a63c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2732fe57347841c79c86f9327e937332",
            "placeholder": "​",
            "style": "IPY_MODEL_86704aeb74794cacb5ed89d140417de3",
            "value": "100%"
          }
        },
        "65e697f960b147089ed52c9feac502f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a7a6aa5ba9254eceb7831d2d45c95fbe",
            "max": 260000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_649332151ce54e67bc38d316d5baada8",
            "value": 260000
          }
        },
        "922691a794f1419b9257a61df129eb0e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_013b60eff3d64c1b8d344e7418df2a5d",
            "placeholder": "​",
            "style": "IPY_MODEL_ba36728079644d9695bc59a20cc7c18f",
            "value": " 260000/260000 [00:04&lt;00:00, 76895.48it/s]"
          }
        },
        "f58479cd143640a981280d248005ddf3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2732fe57347841c79c86f9327e937332": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "86704aeb74794cacb5ed89d140417de3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a7a6aa5ba9254eceb7831d2d45c95fbe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "649332151ce54e67bc38d316d5baada8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "013b60eff3d64c1b8d344e7418df2a5d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ba36728079644d9695bc59a20cc7c18f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}